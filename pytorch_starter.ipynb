{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pytorch入門\n",
    "簡単なmnistサンプルで学ぶ。あえて、convolutionやpoolingは使わない。\n",
    "- 参考：[公式のcifar10サンプル](https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## データ準備"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データの変換用\n",
    "transform = transforms.Compose(\n",
    "    [\n",
    "        # numpy.ndarrayをテンソルに変換\n",
    "        transforms.ToTensor(),\n",
    "        # 平均0.5、標準偏差0.5へ。チャンネル数のタプルで渡す。\n",
    "        transforms.Normalize(mean=(0.5, ), std=(0.5, ))\n",
    "    ]\n",
    ")\n",
    "# 学習データ用意\n",
    "trainset = torchvision.datasets.MNIST(\n",
    "    root='./dataset', # 保存先\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=transform\n",
    ")\n",
    "# 学習用ローダー\n",
    "trainloader = torch.utils.data.DataLoader(\n",
    "    trainset,\n",
    "    batch_size=128,\n",
    "    shuffle=True,\n",
    "    num_workers=2\n",
    ")\n",
    "# テストデータ用意\n",
    "testset = torchvision.datasets.MNIST(\n",
    "    root='./dataset', \n",
    "    train=False, \n",
    "    download=True, \n",
    "    transform=transform\n",
    ")\n",
    "# テスト用ローダー\n",
    "testloader = torch.utils.data.DataLoader(\n",
    "    testset, \n",
    "    batch_size=128,\n",
    "    shuffle=False, \n",
    "    num_workers=2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### データの確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2, 8, 3, 3, 3, 7, 6, 9, 6, 6, 9, 6, 4, 3, 0, 7, 8, 8, 5, 7, 6, 0, 2, 6,\n",
       "        0, 6, 7, 5, 6, 9, 6, 4, 5, 8, 5, 2, 5, 7, 9, 4, 5, 5, 8, 5, 7, 7, 6, 9,\n",
       "        9, 2, 6, 5, 3, 9, 8, 0, 4, 9, 8, 0, 1, 8, 7, 8, 6, 6, 3, 3, 9, 1, 0, 2,\n",
       "        1, 9, 9, 9, 1, 8, 2, 3, 6, 6, 2, 1, 1, 8, 3, 4, 3, 9, 3, 7, 9, 1, 8, 1,\n",
       "        5, 7, 8, 8, 5, 8, 1, 3, 2, 2, 4, 8, 9, 3, 1, 8, 9, 0, 8, 6, 4, 3, 7, 9,\n",
       "        4, 4, 6, 6, 8, 8, 9, 6])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# バッチサイズ分\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 1, 28, 28])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# バッチサイズ x チャンネル数 x height x width\n",
    "images.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## モデル"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# ネットワークの定義\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        # 28x28次元 -> 256次元\n",
    "        self.fc1 = nn.Linear(1*28*28, 256)\n",
    "        # 256次元 -> 10次元（10クラスあるため）\n",
    "        self.fc2 = nn.Linear(256, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # shapeを変形する（バッチサイズ x 次元数）\n",
    "        x = x.view(-1, 1*28*28)\n",
    "        # 線形変換後ReLuをかます\n",
    "        x = F.relu(self.fc1(x))\n",
    "        # 【注意】Kerasだと最後にsoftmaxをかますが、\n",
    "        # pytorchだと損失関数を計算する nn.CrossEntropyLoss の中にsoftmaxの計算が含まれている\n",
    "        # ただし、予測時に確率にしたい場合はアウトプットを nn.functional.softmax() で変換する必要がある\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "# 目的関数\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# 最適化手法\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5bf65e3ed0c14657b4a0af7355611574",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=10.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1, batch:100, loss: 0.6820216017961502\n",
      "epoch:1, batch:200, loss: 0.3693145060539246\n",
      "epoch:1, batch:300, loss: 0.332705043554306\n",
      "epoch:1, batch:400, loss: 0.29559941463172434\n",
      "epoch:2, batch:100, loss: 0.23795114882290364\n",
      "epoch:2, batch:200, loss: 0.20222241077572106\n",
      "epoch:2, batch:300, loss: 0.1960952030867338\n",
      "epoch:2, batch:400, loss: 0.1974168461561203\n",
      "epoch:3, batch:100, loss: 0.15257078558206558\n",
      "epoch:3, batch:200, loss: 0.1440433470159769\n",
      "epoch:3, batch:300, loss: 0.142299246750772\n",
      "epoch:3, batch:400, loss: 0.13810560397803784\n",
      "epoch:4, batch:100, loss: 0.11472118373960256\n",
      "epoch:4, batch:200, loss: 0.10906709022819996\n",
      "epoch:4, batch:300, loss: 0.11881133031100034\n",
      "epoch:4, batch:400, loss: 0.10873796993866564\n",
      "epoch:5, batch:100, loss: 0.09303514676168562\n",
      "epoch:5, batch:200, loss: 0.09735027667135\n",
      "epoch:5, batch:300, loss: 0.09419337672181427\n",
      "epoch:5, batch:400, loss: 0.08241723172366619\n",
      "epoch:6, batch:100, loss: 0.07430373188108205\n",
      "epoch:6, batch:200, loss: 0.07744961531832814\n",
      "epoch:6, batch:300, loss: 0.08326769672334194\n",
      "epoch:6, batch:400, loss: 0.08584574017673731\n",
      "epoch:7, batch:100, loss: 0.06424882810562849\n",
      "epoch:7, batch:200, loss: 0.06734237873926759\n",
      "epoch:7, batch:300, loss: 0.06900943802669644\n",
      "epoch:7, batch:400, loss: 0.06937070047482848\n",
      "epoch:8, batch:100, loss: 0.054583746707066894\n",
      "epoch:8, batch:200, loss: 0.053754752282984555\n",
      "epoch:8, batch:300, loss: 0.05924832190386951\n",
      "epoch:8, batch:400, loss: 0.06599869548343122\n",
      "epoch:9, batch:100, loss: 0.05515550890006125\n",
      "epoch:9, batch:200, loss: 0.04342450499534607\n",
      "epoch:9, batch:300, loss: 0.04817642761394381\n",
      "epoch:9, batch:400, loss: 0.0596773521695286\n",
      "epoch:10, batch:100, loss: 0.044643463375978173\n",
      "epoch:10, batch:200, loss: 0.04772464006673545\n",
      "epoch:10, batch:300, loss: 0.050657869661226866\n",
      "epoch:10, batch:400, loss: 0.0448864839412272\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Kerasやsklearnでいうfit\n",
    "epochs=10\n",
    "varbose=100\n",
    "for epoch in tqdm(range(epochs)):\n",
    "    # 損失（表示用）\n",
    "    running_loss = 0.0\n",
    "    for i, (inputs, labels) in enumerate(trainloader):\n",
    "        # 勾配の初期化\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Netのforwardに基づいて出力が計算される\n",
    "        outputs = net(inputs)\n",
    "        # 損失の計算\n",
    "        loss = criterion(outputs, labels)\n",
    "        # ↑ここまでで計算グラフの構築が行われ、勾配に使う情報が設定される\n",
    "\n",
    "        # 勾配を計算\n",
    "        loss.backward()\n",
    "        # 最適化法に基づいてパラメータ更新\n",
    "        optimizer.step()\n",
    "\n",
    "        # varbose回分の損失の和。item() で値を取り出している\n",
    "        running_loss += loss.item()\n",
    "        if i % varbose == varbose-1:\n",
    "            print(f\"epoch:{epoch + 1}, batch:{i + 1}, loss: {running_loss / varbose}\")\n",
    "            running_loss = 0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 予測"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 97.26\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "# 予測時に勾配更新しないため、no_gradを指定\n",
    "with torch.no_grad():\n",
    "    for (images, labels) in testloader:\n",
    "        # forwardした結果\n",
    "        # これを nn.functional.softmax() すると確率が得られるが、ここでは使わない\n",
    "        outputs = net(images)\n",
    "        # torch.max() は (最大値, そのindex)を返す関数。dimは最大値を見る軸\n",
    "        _, predicted = torch.max(outputs.data, dim=1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "print(f\"Accuracy: {100 * float(correct/total)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPUを使うには\n",
    "コードの書き方だけメモ。環境構築は別のサイトを参照。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cudaが使えるか確認\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# .toメソッドでデバイスに移すようにする\n",
    "# ネットワークに関して\n",
    "net = Net().to(device)\n",
    "# データに関して\n",
    "images, labels = dataiter.next()\n",
    "images, labels = images.to(device), labels.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
